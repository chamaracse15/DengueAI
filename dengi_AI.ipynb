{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 6\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "from statsmodels.tools import eval_measures\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_path, labels_path=None):\n",
    "    # load data and set index to city, year, weekofyear\n",
    "    df = pd.read_csv(data_path, index_col=[0, 1, 2])\n",
    "    \n",
    "    # select features we want\n",
    "    features = ['reanalysis_specific_humidity_g_per_kg', \n",
    "                 'reanalysis_dew_point_temp_k', \n",
    "                 'station_avg_temp_c', \n",
    "                 'station_min_temp_c']\n",
    "    df = df[features]\n",
    "    \n",
    "    # fill missing values\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    # add labels to dataframe\n",
    "    if labels_path:\n",
    "        labels = pd.read_csv(labels_path, index_col=[0, 1, 2])\n",
    "        df = df.join(labels)\n",
    "    \n",
    "    # separate san juan and iquitos\n",
    "    sj = df.loc['sj']\n",
    "    iq = df.loc['iq']\n",
    "    \n",
    "    return sj, iq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_train, iq_train = preprocess_data('./dengue_features_train.csv', labels_path=\"./dengue_labels_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(936, 5)\n",
      "(520, 5)\n"
     ]
    }
   ],
   "source": [
    "print(sj_train.shape)\n",
    "print(iq_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_subtrain = sj_train.head(500)\n",
    "sj_subtest = sj_train.tail(sj_train.shape[0] - 500)\n",
    "\n",
    "iq_subtrain = iq_train.head(300)\n",
    "iq_subtest = iq_train.tail(iq_train.shape[0] - 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generalized liner model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(train, test):\n",
    "    # Step 1: specify the form of the model\n",
    "    model_formula = \"total_cases ~ 1 + reanalysis_specific_humidity_g_per_kg + reanalysis_dew_point_temp_k + \" \\\n",
    "                    \"station_min_temp_c + station_avg_temp_c\"\n",
    "    \n",
    "    grid = 10 ** np.arange(-8, -3, dtype=np.float64)\n",
    "                    \n",
    "    best_alpha = []\n",
    "    best_score = 1000\n",
    "        \n",
    "    # Step 2: Find the best hyper parameter, alpha\n",
    "    for alpha in grid:\n",
    "        \n",
    "        model = smf.glm(formula=model_formula, data=train, \n",
    "                        family=sm.families.NegativeBinomial(alpha=alpha))\n",
    "\n",
    "        results = model.fit()\n",
    "        predictions = results.predict(test).astype(int)\n",
    "        score = eval_measures.meanabs(predictions, test.total_cases)\n",
    "\n",
    "        if score < best_score:\n",
    "            best_alpha = alpha\n",
    "            best_score = score\n",
    "\n",
    "    print('best alpha = ', best_alpha)\n",
    "    print('best score = ', best_score)\n",
    "            \n",
    "    # Step 3: refit on entire dataset\n",
    "    full_dataset = pd.concat([train, test])\n",
    "    model = smf.glm(formula=model_formula,\n",
    "                    data=full_dataset,\n",
    "                    family=sm.families.NegativeBinomial(alpha=best_alpha))\n",
    "\n",
    "    fitted_model = model.fit()\n",
    "    return fitted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weather",
   "language": "python",
   "name": "weather"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
